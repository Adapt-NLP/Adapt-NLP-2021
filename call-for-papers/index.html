<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Call-For-Papers | Adapt-NLP</title>
</head>

<body>

    <div class="banner">
        <img src="assets/banner.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">Adapt</span><span class="title3">-</span><span class="title2">NLP</span> <span class="year">2021</span>
        </div>
        <div class="bottom-right">
            June 31, 2021 <br> Conference name, City Name
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Workshops Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Program" href="program">Program</a> 
            </td>
            <td class="navigation">
                <a class="current" title="Call For Papers" href="call-for-papers">Call For<br>Papers</a> 
            </td>
            <td class="navigation">
                <a title="Program Commitee" href="pc">Program<br>Commitee</a>
            </td>
            <td class="navigation">
                <a title="Organizing Team" href="organizing-team">Organizing<br>Team</a>
            </td>
            <td class="navigation">
                <a title="Submitt a paper for the workshop" href="submissions">Submissions</a>
            </td>
        </tr>
    </table>


    
    <p>
        The growth in computational power and the rise of Deep Neural Networks (DNNs) have revolutionized the field of Natural Language Processing (NLP). 
        The ability to collect massive dataset with the capacity to train big models on powerful GPUs, has yielded NLP-based technology that was beyond 
        imagination only a few years ago.
    </p>
    
    <p>
        However, many NLP algorithms rely on the fundamental assumption that the training and the test sets follow the same underlying distribution. 
        When these distributions do not match, a phenomenon known as domain shift, such models are likely to encounter performance drops. 
        Despite the growing availability  of heterogeneous data, many NLP domains still lack the amounts of labeled data required to feed data-hungry 
        neural models, and in some domains and languages even unlabeled data is scarce. As a result, the problem of domain adaptation, 
        training an algorithm on annotated data from one or more source domain and  applying it to other target domains, is a fundamental NLP challenge.
    </p>
    
    <p>
        The topics of the workshop include, but are not restricted to:
                 
        <ul>
            <li>Novel DA algorithms, for existing as well as new setups.</li> 
            <li>Extending DA research to new domains and tasks through both novel datasets and algorithmic approaches.</li> 
            <li>Proposing novel zero-shot and few-shot  algorithms and discussing their relevance for DA.</li> 
            <li>Exploring the similarities and differences between algorithmic approaches to DA, cross-lingual and cross-task learning.</li> 
            <li>A conceptual discussion of the definitions of fundamental concepts such as domain, transfer as well as zero-shot and few-shot learning.</li> 
            <li>Introducing and exploring novel or under-explored DA setups, aiming towards realistic and applicable ones (e.g., one-to-many DA, many-to-many DA and DA when the target domain is unknown when training on the source domain).</li> 
        </ul>
    </p>

    <table class="footer">
        <tr>
            <td class="footer">Design by<br> <a target="_blank" href="https://eyalbd2.github.io/">Eyal Ben-David</a></td> 
            <td class="footer">&copy; Eyal Ben-David</td> 
        </tr>
    </table>

    </body>
</html>

